"""
ì‡¼í•‘ ì¸ë„¤ì¼ íŒŒì´í”„ë¼ì¸:
1. Link Scraper: Playwrightë¡œ og:image, og:title ì¶”ì¶œ
2. Replicate: ëˆ„ë¼(ë°°ê²½ ì œê±°)
3. Gemini: ìƒí’ˆ ë¶„ì„(JSON) + ë°°ê²½ ìƒì„±
4. PIL: ì œí’ˆ+ë°°ê²½ í•©ì„± â†’ 1000x1000 PNG
"""
from __future__ import annotations

import asyncio
import base64
import io
import json
import os
import re
import time
from typing import Any, Dict, Optional, Tuple

# Optional imports - fail gracefully if not installed
try:
    from playwright.async_api import async_playwright
    HAS_PLAYWRIGHT = True
except ImportError:
    HAS_PLAYWRIGHT = False

try:
    from playwright_stealth import Stealth
    HAS_STEALTH = True
except ImportError:
    HAS_STEALTH = False

try:
    from PIL import Image
    HAS_PIL = True
except ImportError:
    HAS_PIL = False

try:
    import httpx
    HAS_HTTPX = True
except ImportError:
    HAS_HTTPX = False

try:
    import undetected_chromedriver as uc
    HAS_UC = True
except ImportError:
    HAS_UC = False

# rembgëŠ” onnxruntime í•„ìš”. Python 3.14ëŠ” onnxruntime ë¯¸ì§€ì› â†’ import ì‹œ sys.exit(1)ë¡œ í¬ë˜ì‹œí•˜ë¯€ë¡œ ì„ ì²´í¬
try:
    import onnxruntime  # noqa: F401
    from rembg import remove as rembg_remove, new_session as rembg_new_session
    HAS_REMBG = True
except (ImportError, ModuleNotFoundError):
    HAS_REMBG = False
    rembg_remove = None
    rembg_new_session = None


SYSTEM_INSTRUCTION = (
    "ìƒí’ˆì˜ ì›ë˜ í˜•íƒœëŠ” ìœ ì§€í•˜ë©´ì„œ ë°°ê²½ë§Œ ë§ˆë²•ì²˜ëŸ¼ ì–´ìš¸ë¦¬ê²Œ ë°”ê¿”ì¤˜. "
    "Keep the product's original form intact while magically changing only the background to match."
)


def _is_naver_error_page(html: str) -> bool:
    """ë„¤ì´ë²„ ì—ëŸ¬/ì°¨ë‹¨ í˜ì´ì§€ì¸ì§€ í™•ì¸ (ìƒí’ˆ í˜ì´ì§€ê°€ ì•„ë‹˜)."""
    if not html or len(html) < 500:
        return True
    markers = [
        "í˜„ì¬ ì„œë¹„ìŠ¤ ì ‘ì†ì´ ë¶ˆê°€í•©ë‹ˆë‹¤",
        "module_error",
        "ë™ì‹œì— ì ‘ì†í•˜ëŠ” ì´ìš©ì ìˆ˜ê°€ ë§ê±°ë‚˜",
        "ì‹œìŠ¤í…œì˜¤ë¥˜",
        "ì ‘ì†ì´ ë¶ˆê°€í•©ë‹ˆë‹¤",
    ]
    return any(m in html for m in markers)


def _extract_image_from_html(html: str) -> Tuple[Optional[str], Optional[str]]:
    """HTML/ìŠ¤í¬ë¦½íŠ¸ ë‚´ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ (og:image, JSON, ì •ê·œì‹ ë“±)."""
    if _is_naver_error_page(html):
        return (None, None)
    img, title = None, None
    # og:image / og:title
    m = re.search(r'<meta[^>]+property=["\']og:image["\'][^>]+content=["\']([^"\']+)["\']', html, re.I)
    if not m:
        m = re.search(r'<meta[^>]+content=["\']([^"\']+)["\'][^>]+property=["\']og:image["\']', html, re.I)
    if m:
        img = m.group(1).strip()
    m = re.search(r'<meta[^>]+property=["\']og:title["\'][^>]+content=["\']([^"\']+)["\']', html, re.I)
    if not m:
        m = re.search(r'<meta[^>]+content=["\']([^"\']+)["\'][^>]+property=["\']og:title["\']', html, re.I)
    if m:
        title = m.group(1).strip()
    if img and img.startswith("http"):
        return (img, title)
    # img[alt=ëŒ€í‘œì´ë¯¸ì§€]
    if "ëŒ€í‘œì´ë¯¸ì§€" in html:
        m = re.search(r'<img[^>]+alt=["\']ëŒ€í‘œì´ë¯¸ì§€["\'][^>]+src=["\']([^"\']+)["\']', html)
        if not m:
            m = re.search(r'<img[^>]+src=["\']([^"\']+)["\'][^>]+alt=["\']ëŒ€í‘œì´ë¯¸ì§€["\']', html)
        if m and m.group(1).startswith("http"):
            return (m.group(1).strip(), title)
    # shop-phinf URL (HTML ì†ì„±)
    m = re.search(r'(https?://[^"\'<>\s]*(?:shop-phinf|phinf\.pstatic)[^"\'<>\s]*\.(?:jpg|jpeg|png|webp)[^"\'<>\s]*)', html, re.I)
    if m and m.group(1).startswith("http"):
        return (m.group(1).strip(), title)
    # JSON/ìŠ¤í¬ë¦½íŠ¸ ë‚´ ì´ë¯¸ì§€ URL (ì´ìŠ¤ì¼€ì´í”„ í¬í•¨)
    for pat in [
        r'["\'](https?://[^"\']*shop-phinf[^"\']*\.(?:jpg|jpeg|png|webp)[^"\']*)["\']',
        r'"(https?://[^"]*phinf\.pstatic[^"]*\.(?:jpg|jpeg|png|webp)[^"]*)"',
        r'"imageUrl"\s*:\s*"([^"]+)"',
        r'"representativeImage"\s*:\s*"([^"]+)"',
        r'"image"\s*:\s*"([^"]+)"',
        r'"thumbUrl"\s*:\s*"([^"]+)"',
        r'"productImage"\s*:\s*"([^"]+)"',
    ]:
        m = re.search(pat, html, re.I)
        if m:
            u = m.group(1).replace("\\/", "/").strip()
            if u.startswith("http") and ("shop-phinf" in u or "phinf" in u or "pstatic" in u):
                if not re.search(r'logo|icon|banner|ad|spinner|1x1|pixel', u, re.I):
                    return (u, title)
    # ë„“ì€ ë²”ìœ„: pstatic ì´ë¯¸ì§€
    m = re.search(r'(https?://[a-zA-Z0-9.-]*pstatic\.net/[^"\'<>\s]+\.(?:jpg|jpeg|png|webp)[^"\'<>\s]*)', html, re.I)
    if m and m.group(1).startswith("http"):
        u = m.group(1).strip()
        if not re.search(r'logo|icon|banner|ad', u, re.I):
            return (u, title)
    # ë²”ìš©: og:image ì™¸ product/ìƒí’ˆ ì´ë¯¸ì§€ (ë¸Œëœë“œ ì‚¬ì´íŠ¸ ë“±)
    for pat in [
        r'"image"\s*:\s*"([^"]+)"',
        r'"productImage"\s*:\s*"([^"]+)"',
        r'"mainImage"\s*:\s*"([^"]+)"',
        r'"thumbnail"\s*:\s*"([^"]+)"',
        r'data-src=["\']([^"\']+\.(?:jpg|jpeg|png|webp)[^"\']*)["\']',
    ]:
        m = re.search(pat, html, re.I)
        if m:
            u = m.group(1).replace("\\/", "/").strip()
            if u.startswith("http") and not re.search(r'logo|icon|banner|ad|spinner|1x1|pixel', u, re.I):
                return (u, title)
    return (None, title)


def _scrape_with_uc(url: str, headless: bool = True) -> Tuple[Optional[str], Optional[str]]:
    """undetected-chromedriverë¡œ í¬ë¡¤ë§ (ë„¤ì´ë²„ ë´‡ ì°¨ë‹¨ ìš°íšŒ). naver.com ë¨¼ì € ë°©ë¬¸ í›„ ìƒí’ˆí˜ì´ì§€."""
    if not HAS_UC:
        return (None, None)
    try:
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from selenium.webdriver.common.by import By

        options = uc.ChromeOptions()
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_argument("--lang=ko-KR")
        options.add_argument("--window-position=-2400,-2400")
        driver = uc.Chrome(options=options, headless=headless, use_subprocess=True)
        try:
            if "smartstore.naver.com" in url or "brand.naver.com" in url or "shopping.naver.com" in url:
                driver.get("https://www.naver.com")
                time.sleep(1)
            driver.get(url)
            wait = WebDriverWait(driver, 12)
            try:
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'img[alt="ëŒ€í‘œì´ë¯¸ì§€"], img[src*="shop-phinf"], meta[property="og:image"]')))
            except Exception:
                pass
            time.sleep(2)
            driver.execute_script("window.scrollTo(0, 400);")
            time.sleep(1)
            img = driver.execute_script("""
                var rep = document.querySelector('img[alt="ëŒ€í‘œì´ë¯¸ì§€"]');
                if (rep && rep.src) return rep.src;
                var og = document.querySelector('meta[property="og:image"]');
                if (og && og.content) return og.content;
                var imgs = document.querySelectorAll('img[src*="shop-phinf.pstatic.net"], img[src*="phinf.pstatic"]');
                for (var i=0; i<imgs.length; i++) {
                    var s = imgs[i].src || '';
                    if (s && !/logo|icon|banner|ad/i.test(s)) return s;
                }
                var all = document.querySelectorAll('img[src]');
                for (var i=0; i<all.length; i++) {
                    var s = all[i].src || '';
                    if (s && /shop-phinf|phinf\\.pstatic/i.test(s)) return s;
                }
                return null;
            """)
            title = driver.execute_script("""
                var og = document.querySelector('meta[property="og:title"]');
                return og ? og.content : null;
            """)
            if img and str(img).startswith("http"):
                return (str(img).strip(), str(title).strip() if title else None)
        finally:
            driver.quit()
    except Exception:
        pass
    return (None, None)


def _try_naver_search_api(product_id: str, client_id: str, client_secret: str) -> Tuple[Optional[str], Optional[str]]:
    """ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ APIë¡œ ìƒí’ˆ ì´ë¯¸ì§€ ì¡°íšŒ (productIdë¡œ ê²€ìƒ‰ ì‹œë„)."""
    if not HAS_HTTPX or not product_id or not client_id or not client_secret:
        return (None, None)
    try:
        with httpx.Client(timeout=15) as client:
            r = client.get(
                "https://openapi.naver.com/v1/search/shop.json",
                params={"query": product_id, "display": 10},
                headers={"X-Naver-Client-Id": client_id, "X-Naver-Client-Secret": client_secret},
            )
            r.raise_for_status()
            data = r.json()
            for item in data.get("items", []):
                if str(item.get("productId")) == str(product_id):
                    img = item.get("image")
                    title = item.get("title", "").replace("<b>", "").replace("</b>", "")
                    if img and img.startswith("http"):
                        return (img, title or None)
            if data.get("items"):
                first = data["items"][0]
                if first.get("image", "").startswith("http"):
                    return (first["image"], first.get("title", "").replace("<b>", "").replace("</b>", "") or None)
    except Exception:
        pass
    return (None, None)


async def scrape_naver_product(
    url: str,
    naver_client_id: Optional[str] = None,
    naver_client_secret: Optional[str] = None,
) -> Tuple[Optional[str], Optional[str]]:
    """httpx(ë¹ ë¦„) â†’ undetected-chromedriver â†’ Playwright â†’ ëª¨ë°”ì¼ URL â†’ Naver API. ë¬´ì¡°ê±´ í¬ë¡¤ë§ ì„±ê³µ ëª©í‘œ."""
    # 0. httpx ë¨¼ì € ì‹œë„ (ê°€ë²¼ì›€, ì¼ë¶€ í˜ì´ì§€ëŠ” ì´ˆê¸° HTMLì— ì´ë¯¸ì§€ í¬í•¨)
    if HAS_HTTPX:
        urls_to_try = [url]
        if "smartstore.naver.com" in url and "m.smartstore" not in url:
            urls_to_try.insert(0, url.replace("smartstore.naver.com", "m.smartstore.naver.com"))
        for try_url in urls_to_try:
            try:
                async with httpx.AsyncClient(
                    timeout=8.0, follow_redirects=True,
                    headers={
                        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
                        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
                        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
                    },
                ) as client:
                    r = await client.get(try_url)
                    r.raise_for_status()
                    img, title = _extract_image_from_html(r.text)
                    if img and img.startswith("http"):
                        return (img, title)
            except Exception:
                pass

    # 1. Playwright ë¨¼ì € (UCë³´ë‹¤ ë¹ ë¦„, domcontentloaded + og:image ì¦‰ì‹œ ì¶”ì¶œ)
    if HAS_PLAYWRIGHT:
        try:
            if HAS_STEALTH:
                pw_ctx = Stealth().use_async(async_playwright())
            else:
                pw_ctx = async_playwright()
            async with pw_ctx as p:
                try:
                    browser = await p.chromium.launch(channel="chrome", headless=True)
                except Exception:
                    browser = await p.chromium.launch(
                        headless=True,
                        args=["--disable-blink-features=AutomationControlled", "--disable-dev-shm-usage", "--no-sandbox"],
                    )
                context = await browser.new_context(
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
                    viewport={"width": 1920, "height": 1080},
                    locale="ko-KR",
                    extra_http_headers={
                        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
                        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
                        "Sec-Ch-Ua": '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
                        "Sec-Ch-Ua-Mobile": "?0",
                        "Sec-Ch-Ua-Platform": '"Windows"',
                    },
                )
                page = await context.new_page()
                captured: list = []

                async def on_response(resp):
                    try:
                        if resp.url and ("product" in resp.url.lower() or "api" in resp.url or "graphql" in resp.url) and resp.status == 200:
                            ct = resp.headers.get("content-type", "")
                            if "json" in ct:
                                body = await resp.text()
                                if body and ("image" in body.lower() or "shop-phinf" in body or "phinf" in body):
                                    captured.append(body)
                    except Exception:
                        pass

                page.on("response", on_response)
                # 1) ìƒí’ˆ í˜ì´ì§€ ì§ì ‘ ë°©ë¬¸ (naver ì„ ë°©ë¬¸ ìƒëµ ì‹œë„ - ë” ë¹ ë¦„)
                await page.goto(url, wait_until="domcontentloaded", timeout=15000)
                await page.wait_for_timeout(2000)
                try:
                    og_img = await page.locator('meta[property="og:image"]').get_attribute("content")
                    og_title = await page.locator('meta[property="og:title"]').get_attribute("content")
                    if og_img and og_img.startswith("http"):
                        await browser.close()
                        return (og_img.strip(), og_title.strip() if og_title else None)
                except Exception:
                    pass
                # 2) ì‹¤íŒ¨ ì‹œ naver ì„ ë°©ë¬¸ í›„ ì¬ì‹œë„
                if "smartstore.naver.com" in url or "brand.naver.com" in url or "shopping.naver.com" in url:
                    await page.goto("https://www.naver.com", wait_until="domcontentloaded", timeout=8000)
                    await page.wait_for_timeout(1500)
                    await page.goto(url, wait_until="domcontentloaded", timeout=15000)
                    await page.wait_for_timeout(2500)
                try:
                    og_img = await page.locator('meta[property="og:image"]').get_attribute("content")
                    og_title = await page.locator('meta[property="og:title"]').get_attribute("content")
                    if og_img and og_img.startswith("http"):
                        await browser.close()
                        return (og_img.strip(), og_title.strip() if og_title else None)
                except Exception:
                    pass
                await page.evaluate("window.scrollTo(0, 400)")
                await page.wait_for_timeout(1000)
                img, title = await page.evaluate("""() => {
                    let img = null, title = null;
                    const tryImg = (s) => { if (s && s.startsWith('http') && !/logo|icon|banner|ad|spinner|1x1|pixel/i.test(s)) return s; return null; };
                    const repImg = document.querySelector('img[alt="ëŒ€í‘œì´ë¯¸ì§€"]');
                    if (repImg) img = tryImg(repImg.src || repImg.getAttribute('data-src') || repImg.getAttribute('data-original'));
                    if (!img) {
                        const ogImg = document.querySelector('meta[property="og:image"]');
                        if (ogImg && ogImg.content) img = ogImg.content;
                    }
                    const ogTitle = document.querySelector('meta[property="og:title"]');
                    if (ogTitle && ogTitle.content) title = ogTitle.content;
                    if (!img) {
                        const selectors = [
                            'img[src*="shop-phinf.pstatic.net"]', 'img[src*="shop-phinf"]', 'img[src*="phinf.pstatic"]', 'img[src*="pstatic.net"]',
                            'img[data-src*="shop-phinf"]', 'img[data-src*="phinf"]', 'img[data-original*="phinf"]',
                            '[class*="product"] img', '[class*="Product"] img', '[class*="thumb"] img',
                            '[class*="goods"] img', '[class*="detail"] img', '[class*="slick"] img',
                            'main img', '[role="main"] img', '.product-detail img', '#content img'
                        ];
                        for (const sel of selectors) {
                            const el = document.querySelector(sel);
                            if (el) {
                                const s = (el.src || el.getAttribute('data-src') || el.getAttribute('data-original') || '').trim();
                                img = tryImg(s); if (img) break;
                            }
                        }
                    }
                    if (!img) {
                        const all = document.querySelectorAll('img[src]');
                        for (const el of all) {
                            const s = (el.src || '').trim();
                            if (s && /phinf|pstatic|shop-phinf|naver.*image/i.test(s) && !/logo|icon|banner|ad/i.test(s)) {
                                img = s; break;
                            }
                        }
                    }
                    if (!img) {
                        const first = document.querySelector('img[src^="http"][width], img[src^="http"][height]');
                        if (first && (first.naturalWidth || 0) >= 200) img = first.src;
                    }
                    return [img || null, title || null];
                }""")
                if not img and captured:
                    for body in captured:
                        img2, _ = _extract_image_from_html(body)
                        if img2:
                            img, title = img2, title or None
                            break
                await browser.close()
                if img and str(img).startswith("http"):
                    return (str(img).strip(), str(title).strip() if title else None)
        except Exception:
            pass

    # 2. undetected-chromedriver (Playwright ì‹¤íŒ¨ ì‹œ, ë´‡ ì°¨ë‹¨ ìš°íšŒìš© - 25ì´ˆ ì†Œìš”)
    if HAS_UC:
        try:
            result = await asyncio.to_thread(_scrape_with_uc, url, True)
            if result[0]:
                return result
        except Exception:
            pass

    # 3. ëª¨ë°”ì¼ URL ì¬ì‹œë„ (10ì´ˆ ì œí•œ)
    if "smartstore.naver.com" in url and "m.smartstore" not in url:
        mobile_url = url.replace("smartstore.naver.com", "m.smartstore.naver.com")
        try:
            result = await asyncio.wait_for(
                scrape_naver_product(mobile_url, naver_client_id, naver_client_secret),
                timeout=12.0,
            )
            if result[0]:
                return result
        except asyncio.TimeoutError:
            pass

    # 4. ë„¤ì´ë²„ ì‡¼í•‘ ê²€ìƒ‰ API (productId ì¶”ì¶œ í›„ ê²€ìƒ‰)
    if naver_client_id and naver_client_secret:
        m = re.search(r"/products/(\d+)", url)
        if m:
            pid = m.group(1)
            result = await asyncio.to_thread(
                _try_naver_search_api, pid, naver_client_id, naver_client_secret
            )
            if result[0]:
                return result

    return (None, None)


_REMBG_SESSION: Optional[Any] = None


def _get_rembg_session():
    """ê³ í’ˆì§ˆ: bria-rmbg(ì´ì»¤ë¨¸ìŠ¤ ìµœì ) â†’ birefnet-general â†’ isnet. REMBG_QUALITY=balanced ì‹œ ê°€ë²¼ìš´ ëª¨ë¸ ìš°ì„ ."""
    global _REMBG_SESSION
    if _REMBG_SESSION is not None:
        return _REMBG_SESSION
    if not rembg_new_session:
        return None
    quality = os.environ.get("REMBG_QUALITY", "high").lower()
    if quality in ("balanced", "low"):
        models = ("isnet-general-use", "u2net", "bria-rmbg")
    else:
        models = ("bria-rmbg", "birefnet-general", "isnet-general-use", "u2net")
    for model in models:
        try:
            _REMBG_SESSION = rembg_new_session(model)
            return _REMBG_SESSION
        except Exception:
            continue
    return None


def remove_background_local(image_bytes: bytes) -> Tuple[Optional[bytes], Optional[str]]:
    """ë¡œì»¬ rembgë¡œ ë°°ê²½ ì œê±°. bria-rmbg + 2048í•´ìƒë„ + alpha_mattingìœ¼ë¡œ ê³ í’ˆì§ˆ ëˆ„ë¼."""
    if not HAS_REMBG or not HAS_PIL:
        return (None, "rembg ë˜ëŠ” Pillow ë¯¸ì„¤ì¹˜")
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        w, h = img.size
        quality = os.environ.get("REMBG_QUALITY", "high").lower()
        max_side = 2560 if quality == "ultra" else (2048 if quality == "high" else 1536)
        if max(w, h) > max_side:
            ratio = max_side / max(w, h)
            img = img.resize((int(w * ratio), int(h * ratio)), Image.Resampling.LANCZOS)
        session = _get_rembg_session()
        # high ëª¨ë“œ: post_process_mask=False (bria 256ë‹¨ê³„ ë§ˆìŠ¤í¬ ë³´ì¡´, morphologicalë¡œ ë””í…Œì¼ ì†ì‹¤ ë°©ì§€)
        use_post = os.environ.get("REMBG_POST_PROCESS", "0").lower() in ("1", "true", "yes")
        out = rembg_remove(
            img,
            session=session,
            alpha_matting=True,
            alpha_matting_foreground_threshold=245,
            alpha_matting_background_threshold=8,
            alpha_matting_erode_size=3,  # 3: ë³‘/í™”ì¥í’ˆ ë“± ì„ ëª…í•œ ì—£ì§€ì— ìµœì 
            post_process_mask=use_post,
        )
        buf = io.BytesIO()
        out.save(buf, format="PNG")
        return (buf.getvalue(), None)
    except ModuleNotFoundError as e:
        if "onnxruntime" in str(e):
            return (None, "onnxruntime ë¯¸ì„¤ì¹˜. Python 3.11/3.12 ì‚¬ìš© ë˜ëŠ” Replicate í† í°ìœ¼ë¡œ ëŒ€ì²´.")
        return (None, f"ë¡œì»¬ ëˆ„ë¼ ì‹¤íŒ¨: {str(e)[:80]}")
    except Exception as e:
        return (None, f"ë¡œì»¬ ëˆ„ë¼ ì‹¤íŒ¨: {str(e)[:80]}")


def _download_image_bytes(image_url: str) -> Optional[bytes]:
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ. bytes ë°˜í™˜."""
    if not HAS_HTTPX:
        return None
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/131.0.0.0 Safari/537.36",
            "Referer": "https://smartstore.naver.com/",
            "Accept": "image/*,*/*;q=0.8",
        }
        with httpx.Client(timeout=30, follow_redirects=True) as client:
            r = client.get(image_url, headers=headers)
            r.raise_for_status()
            return r.content
    except Exception:
        return None


def _download_image_for_replicate(image_url: str) -> Optional[Tuple[bytes, str]]:
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ. (bytes, mime_type) ë°˜í™˜. ë„¤ì´ë²„ CDNì€ Referer í•„ìš”."""
    if not HAS_HTTPX:
        return None
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/131.0.0.0 Safari/537.36",
            "Referer": "https://smartstore.naver.com/",
            "Accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
        }
        with httpx.Client(timeout=30, follow_redirects=True) as client:
            r = client.get(image_url, headers=headers)
            r.raise_for_status()
            content = r.content
            ct = r.headers.get("content-type", "image/jpeg")
            mime = "image/jpeg" if "jpeg" in ct or "jpg" in ct else "image/png" if "png" in ct else "image/webp" if "webp" in ct else "image/jpeg"
            return (content, mime)
    except Exception:
        return None


# Replicate ëª¨ë¸: Bria RMBG 2.0 (256ë‹¨ê³„ íˆ¬ëª…ë„, ì´ì»¤ë¨¸ìŠ¤ ìµœì ) â†’ rembg í´ë°±
_REPLICATE_BRIA_VERSION = "063d41e5fbec2dcce4fa4ab5657f3ade0bf2c2625c73286a34af51cb181189c5"
_REPLICATE_REMBG_VERSION = "fb8af171cfa1616ddcf1242c093f9c46bcada5ad4cf6f2fbe8b81b330ec5c003"


def _replicate_remove(image_input: str, replicate_token: str, version: str) -> Tuple[Optional[bytes], Optional[str]]:
    """Replicate API í˜¸ì¶œ. (ê²°ê³¼, ì˜¤ë¥˜ë©”ì‹œì§€) ë°˜í™˜."""
    if not HAS_HTTPX:
        return (None, "httpx ë¯¸ì„¤ì¹˜")
    try:
        with httpx.Client(timeout=90) as client:
            r = client.post(
                "https://api.replicate.com/v1/predictions",
                headers={
                    "Authorization": f"Bearer {replicate_token}",
                    "Content-Type": "application/json",
                    "Prefer": "wait=60",
                },
                json={"version": version, "input": {"image": image_input}},
            )
            if r.status_code in (401, 403):
                return (None, f"Replicate API ì¸ì¦ ì‹¤íŒ¨ (HTTP {r.status_code}). í† í°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            if r.status_code not in (200, 201):
                try:
                    err = r.json()
                    detail = err.get("detail", str(err))[:150]
                except Exception:
                    detail = r.text[:150]
                return (None, f"Replicate ì˜¤ë¥˜ (HTTP {r.status_code}): {detail}")
            r.raise_for_status()
            data = r.json()
            out_url = data.get("output")
            if not out_url and data.get("status") in ("starting", "processing"):
                get_url = data.get("urls", {}).get("get")
                for _ in range(60):
                    time.sleep(1)
                    r2 = client.get(get_url, headers={"Authorization": f"Bearer {replicate_token}"})
                    r2.raise_for_status()
                    data = r2.json()
                    out_url = data.get("output")
                    if data.get("status") == "failed":
                        err = data.get("error", str(data))[:150]
                        return (None, f"Replicate ì²˜ë¦¬ ì‹¤íŒ¨: {err}")
                    if out_url or data.get("status") == "succeeded":
                        break
            if out_url and isinstance(out_url, str) and out_url.startswith("http"):
                r3 = client.get(out_url)
                r3.raise_for_status()
                return (r3.content, None)
            if isinstance(out_url, dict) and out_url.get("url"):
                r3 = client.get(out_url["url"])
                r3.raise_for_status()
                return (r3.content, None)
            return (None, "Replicate ì¶œë ¥ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except httpx.TimeoutException:
        return (None, "Replicate ìš”ì²­ ì‹œê°„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        return (None, f"Replicate ì˜¤ë¥˜: {str(e)[:120]}")


def remove_background_replicate(image_url: str, replicate_token: str) -> Tuple[Optional[bytes], Optional[str]]:
    """Replicateë¡œ ë°°ê²½ ì œê±°. Bria RMBG 2.0 ìš°ì„  â†’ rembg í´ë°±."""
    if not HAS_HTTPX:
        return (None, "httpx ë¯¸ì„¤ì¹˜")
    image_input = image_url
    if "pstatic.net" in image_url or "naver" in image_url.lower():
        downloaded = _download_image_for_replicate(image_url)
        if downloaded:
            raw, mime = downloaded
            if len(raw) < 5 * 1024 * 1024:
                image_input = f"data:{mime};base64,{base64.b64encode(raw).decode()}"
        else:
            return (None, "ë„¤ì´ë²„ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (CDN ì ‘ê·¼ ë¶ˆê°€)")
    # Bria RMBG 2.0 ìš°ì„  (256ë‹¨ê³„ íˆ¬ëª…ë„, ìƒí’ˆ ìµœì )
    result, err = _replicate_remove(image_input, replicate_token, _REPLICATE_BRIA_VERSION)
    if result:
        return (result, None)
    # rembg í´ë°±
    result, err2 = _replicate_remove(image_input, replicate_token, _REPLICATE_REMBG_VERSION)
    return (result, None) if result else (None, err or err2)


def _gemini_rest_generate(
    api_key: str,
    model: str,
    parts: list,
    generation_config: Optional[Dict[str, Any]] = None,
) -> Optional[dict]:
    """Gemini REST API ì§ì ‘ í˜¸ì¶œ (google-genai ë¼ì´ë¸ŒëŸ¬ë¦¬ 'previous' ì˜¤ë¥˜ ìš°íšŒ)."""
    if not HAS_HTTPX:
        return None
    try:
        payload: Dict[str, Any] = {"contents": [{"parts": parts}]}
        if generation_config:
            payload["generationConfig"] = generation_config
        with httpx.Client(timeout=90) as client:
            r = client.post(
                f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent",
                headers={"x-goog-api-key": api_key, "Content-Type": "application/json"},
                json=payload,
            )
            r.raise_for_status()
            return r.json()
    except Exception:
        return None


def analyze_product_gemini(
    image_base64: str,
    product_title: str,
    gemini_api_key: str,
) -> Optional[Dict[str, Any]]:
    """Geminië¡œ ìƒí’ˆ ë¶„ì„ â†’ JSON (category, core_colors, background_concept)."""
    try:
        prompt = f"""ë‹¤ìŒ ìƒí’ˆ ì´ë¯¸ì§€ì™€ ìƒí’ˆëª…ì„ ë¶„ì„í•´ì„œ, ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì¤˜. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ.

ìƒí’ˆëª…: {product_title or '(ì—†ìŒ)'}

JSON í˜•ì‹:
{{
  "category": "ìƒí’ˆ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: í™”ì¥í’ˆ, íŒ¨ì…˜, ì‹í’ˆ ë“±)",
  "core_colors": ["#hex1", "#hex2", "#hex3"],
  "background_concept": "ì´ ìƒí’ˆì— ì–´ìš¸ë¦¬ëŠ” ë°°ê²½ (ì˜ˆ: ë¶€ë“œëŸ¬ìš´ ê·¸ë¼ë°ì´ì…˜, ì€ì€í•œ í…ìŠ¤ì²˜. ì œí’ˆ ëˆ„ë¼ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì–´ìš¸ë¦¬ë„ë¡ ë‹¨ìˆœí•˜ê³  í‰í‰í•œ ëŠë‚Œ)"
}}
core_colorsëŠ” ë°˜ë“œì‹œ hex ì½”ë“œ(ì˜ˆ: #ffcc00, #e8f4f8)ë¡œ, ì œí’ˆì˜ ëŒ€í‘œ ìƒ‰ìƒ 2~3ê°œë¥¼ ë„£ì–´ì¤˜."""
        resp = _gemini_rest_generate(
            gemini_api_key,
            "gemini-2.0-flash",
            [
                {"inline_data": {"mime_type": "image/png", "data": image_base64}},
                {"text": prompt},
            ],
        )
        if not resp:
            return None
        text = ""
        for c in resp.get("candidates", []):
            for p in c.get("content", {}).get("parts", []):
                if "text" in p:
                    text += p.get("text", "")
        text = text.strip()
        m = re.search(r"\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}", text, re.DOTALL) or re.search(r"\{[^{}]*\}", text)
        if m:
            return json.loads(m.group())
        return None
    except Exception:
        return None


def generate_background_gemini(
    concept: Dict[str, Any],
    gemini_api_key: str,
) -> Optional[bytes]:
    """Gemini ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ë¡œ ë°°ê²½ ìƒì„±. 1000x1000 PNG."""
    try:
        bg = concept.get("background_concept", "ë¯¸ë‹ˆë©€í•˜ê³  ê¹”ë”í•œ ê´‘ê³  ë°°ê²½")
        colors = concept.get("core_colors", [])
        color_str = ", ".join(colors[:3]) if colors else ""
        prompt = (
            f"Create a 1000x1000 square background for product thumbnail. "
            f"Concept: {bg}. "
            f"Colors: {color_str or 'soft neutral'}. "
            f"Flat, soft gradient or subtle texture only. No dramatic lighting, no spotlights, no strong shadows. "
            f"No text, no products, no people. "
            f"Must blend naturally with product cutout placed on top - avoid complex scenes that clash with cutouts."
        )
        # gemini-2.5-flash-image: ì´ë¯¸ì§€ ìƒì„± ì „ìš© ëª¨ë¸ (responseModalities í•„ìš”)
        img_config = {"responseModalities": ["TEXT", "IMAGE"]}
        resp = _gemini_rest_generate(
            gemini_api_key,
            "gemini-2.5-flash-image",
            [{"text": prompt}],
            generation_config=img_config,
        )
        if not resp:
            # í´ë°±: gemini-3-pro-image-preview
            resp = _gemini_rest_generate(
                gemini_api_key,
                "gemini-3-pro-image-preview",
                [{"text": prompt}],
                generation_config=img_config,
            )
        if not resp:
            return None
        for c in resp.get("candidates", []):
            for p in c.get("content", {}).get("parts", []):
                inline = p.get("inlineData") or p.get("inline_data")
                if inline:
                    b64 = inline.get("data")
                    if b64:
                        return base64.b64decode(b64)
        return None
    except Exception:
        return None


def _parse_hex(c: str) -> Optional[Tuple[int, int, int]]:
    """hex ë¬¸ìì—´ì„ RGB íŠœí”Œë¡œ. #ffcc00 ë˜ëŠ” ffcc00 í˜•ì‹."""
    try:
        h = str(c).strip().lstrip("#")
        if len(h) == 6 and all(x in "0123456789abcdefABCDEF" for x in h):
            return (int(h[0:2], 16), int(h[2:4], 16), int(h[4:6], 16))
    except Exception:
        pass
    return None


def _extract_dominant_colors(image_bytes: bytes, n: int = 2) -> list:
    """ì œí’ˆ ì´ë¯¸ì§€ì—ì„œ ëŒ€í‘œ ìƒ‰ìƒ ì¶”ì¶œ. (í°ìƒ‰/íˆ¬ëª… ì œì™¸)"""
    if not HAS_PIL:
        return []
    try:
        img = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        img = img.resize((50, 50), Image.Resampling.LANCZOS)
        px = img.load()
        colors: Dict[Tuple[int, int, int], int] = {}
        for y in range(50):
            for x in range(50):
                r, g, b = px[x, y]
                if r + g + b < 720 and r + g + b > 30:  # ë„ˆë¬´ ë°ê±°ë‚˜ ì–´ë‘¡ì§€ ì•Šì€ ìƒ‰
                    rgb = (r // 16 * 16, g // 16 * 16, b // 16 * 16)
                    colors[rgb] = colors.get(rgb, 0) + 1
        sorted_colors = sorted(colors.items(), key=lambda x: -x[1])[:n]
        return [c for c, _ in sorted_colors]
    except Exception:
        return []


def _make_gradient_bg(colors: Optional[list] = None, product_bytes: Optional[bytes] = None) -> Optional["Image.Image"]:
    """ì œí’ˆ ìƒ‰ìƒ ê¸°ë°˜ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½. ìƒë‹¨ ë°ìŒ â†’ í•˜ë‹¨ ì œí’ˆ í†¤."""
    if not HAS_PIL:
        return None
    top, bottom = (255, 253, 255), (225, 220, 238)  # ê¸°ë³¸(íšŒìƒ‰) í´ë°±
    rgb_top, rgb_bottom = None, None
    if colors:
        parsed = [_parse_hex(c) for c in colors[:3] if _parse_hex(str(c))]
        if len(parsed) >= 2:
            rgb_top, rgb_bottom = parsed[0], parsed[1]
        elif len(parsed) == 1:
            r, g, b = parsed[0]
            rgb_top = (min(255, r + 60), min(255, g + 55), min(255, b + 60))
            rgb_bottom = (max(0, r - 30), max(0, g - 30), max(0, b - 20))
    if not rgb_top and product_bytes:
        extracted = _extract_dominant_colors(product_bytes, 2)
        if len(extracted) >= 2:
            rgb_top = tuple(min(255, c + 80) for c in extracted[0])
            rgb_bottom = tuple(max(0, c - 40) for c in extracted[1])
        elif len(extracted) == 1:
            r, g, b = extracted[0]
            rgb_top = (min(255, r + 80), min(255, g + 75), min(255, b + 80))
            rgb_bottom = (max(0, r - 50), max(0, g - 50), max(0, b - 40))
    if rgb_top:
        top = tuple(min(255, max(0, c)) for c in rgb_top)
    if rgb_bottom:
        bottom = tuple(min(255, max(0, c)) for c in rgb_bottom)
    img = Image.new("RGB", (1000, 1000))
    px = img.load()
    for y in range(1000):
        t = y / 999
        rgb = tuple(int(top[i] * (1 - t) + bottom[i] * t) for i in range(3))
        for x in range(1000):
            px[x, y] = rgb
    return img.convert("RGBA")


def composite_thumbnail(product_png: bytes, background_png: bytes, core_colors: Optional[list] = None) -> Optional[bytes]:
    """ì œí’ˆ(ëˆ„ë¼)ì„ ë°°ê²½ ìœ„ì— í•©ì„±. 1000x1000 PNG. ëˆ„ë¼ ë†’ì´ 980 ë§ì¶¤."""
    if not HAS_PIL:
        return None
    try:
        bg = Image.open(io.BytesIO(background_png)).convert("RGBA")
        bg = bg.resize((1000, 1000), Image.Resampling.LANCZOS)

        product = Image.open(io.BytesIO(product_png)).convert("RGBA")
        # ì œí’ˆì„ ë¶‰ì€ ë°•ìŠ¤ í¬ê¸° ìˆ˜ì¤€ìœ¼ë¡œ (ìº”ë²„ìŠ¤ì— ê½‰ ì°¨ê²Œ, 1000x1000)
        ratio = min(1000 / product.height, 1000 / product.width, 1.0)
        nw, nh = int(product.width * ratio), int(product.height * ratio)
        product = product.resize((nw, nh), Image.Resampling.LANCZOS)

        x = (1000 - nw) // 2
        y = (1000 - nh) // 2

        # ì•ŒíŒŒ ì—£ì§€ ì •ì œ: halo ì œê±° + 256ë‹¨ê³„ íˆ¬ëª…ë„ ë³´ì¡´ (bria-rmbg í’ˆì§ˆ í™œìš©)
        r, g, b, a = product.split()

        def _refine_alpha(v: int) -> int:
            if v < 95:
                return 0
            if v >= 250:
                return 255
            return int((v - 95) * 255 / (250 - 95))

        a = a.point(_refine_alpha, mode="L")
        product = Image.merge("RGBA", (r, g, b, a))

        bg.paste(product, (x, y), product)

        out = io.BytesIO()
        bg.convert("RGB").save(out, format="PNG", quality=95)
        return out.getvalue()
    except Exception:
        return None


async def run_pipeline(
    url: str,
    gemini_api_key: str,
    replicate_token: str,
    on_progress: Optional[callable] = None,
    naver_client_id: Optional[str] = None,
    naver_client_secret: Optional[str] = None,
    image_url: Optional[str] = None,
) -> Tuple[Optional[str], Optional[str]]:
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰. (result_data_url, error_message)
    image_url ìˆìœ¼ë©´ ìŠ¤í¬ë˜í•‘ ê±´ë„ˆëœ€.
    """
    import asyncio

    # 1. ì´ë¯¸ì§€ í™•ë³´ (URL ë‹¤ìš´ë¡œë“œ / ë¡œì»¬ íŒŒì¼ / í¬ë¡¤ë§)
    if on_progress:
        on_progress("scrape", 5)
    img_url, title = None, None
    img_bytes = None  # ë¡œì»¬ íŒŒì¼ìš©

    if image_url:
        raw = image_url.strip().strip('"').strip("'")
        if raw.startswith("http://") or raw.startswith("https://"):
            img_url = raw
        else:
            # ë¡œì»¬ íŒŒì¼ ê²½ë¡œ ì‹œë„
            from pathlib import Path
            p = Path(raw)
            if p.exists() and p.is_file():
                try:
                    img_bytes = p.read_bytes()
                except Exception:
                    pass
            if not img_bytes:
                return (None, "ì´ë¯¸ì§€ URL(https://...) ë˜ëŠ” ë¡œì»¬ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆ: https://shop-phinf.pstatic.net/... ë˜ëŠ” C:\\Users\\...\\image.jpg")

    if not img_url and not img_bytes:
        if url and (url.startswith("http://") or url.startswith("https://")):
            try:
                img_url, title = await asyncio.wait_for(
                    scrape_naver_product(url, naver_client_id=naver_client_id, naver_client_secret=naver_client_secret),
                    timeout=50.0,
                )
            except asyncio.TimeoutError:
                img_url, title = None, None
        if not img_url:
            return (None, "ìƒí’ˆ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ URL(https://...)ì„ ì§ì ‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    if on_progress:
        on_progress("rembg", 20)

    # 2. ëˆ„ë¼: ë¡œì»¬ rembg ìš°ì„  (ë¬´ë£Œ, 10~15ì´ˆ) â†’ Replicate í´ë°± (ìœ ë£Œ, 402 ì‹œ í¬ë ˆë”§ í•„ìš”)
    product_png = None
    rembg_err = None

    if HAS_REMBG:
        def _local():
            raw = img_bytes if img_bytes else _download_image_bytes(img_url)
            if raw:
                return remove_background_local(raw)
            return (None, "ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨" if img_url else "ë¡œì»¬ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨")
        product_png, rembg_err = await asyncio.to_thread(_local)

    if not product_png and replicate_token and img_url:
        def _replicate():
            return remove_background_replicate(img_url, replicate_token)
        product_png, rembg_err = await asyncio.to_thread(_replicate)

    if not product_png:
        if not HAS_REMBG and not replicate_token:
            return (None, "ëˆ„ë¼ ì²˜ë¦¬ ë¶ˆê°€: rembg ì„¤ì¹˜(pip install rembg) ë˜ëŠ” Replicate í† í° í•„ìš”")
        if rembg_err and "402" in rembg_err:
            return (None, rembg_err + "\n\nğŸ’³ Replicate í¬ë ˆë”§ ì¶©ì „: https://replicate.com/account/billing")
        return (None, rembg_err or "ëˆ„ë¼ ì²˜ë¦¬ ì‹¤íŒ¨")

    if on_progress:
        on_progress("analyze", 40)

    # 3. Gemini ë¶„ì„ (blocking)
    b64 = base64.b64encode(product_png).decode()
    concept = await asyncio.to_thread(
        analyze_product_gemini, b64, title or "", gemini_api_key
    )
    if not concept:
        concept = {
            "category": "ìƒí’ˆ",
            "core_colors": ["#ffffff"],
            "background_concept": "ë¯¸ë‹ˆë©€ í™”ì´íŠ¸ ë°°ê²½",
        }

    if on_progress:
        on_progress("background", 60)

    # 4. ë°°ê²½ ìƒì„± (blocking)
    bg_png = await asyncio.to_thread(
        generate_background_gemini, concept, gemini_api_key
    )
    if not bg_png and HAS_PIL:
        # Gemini ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ ì‹œ: ì€ì€í•œ ê·¸ë¼ë°ì´ì…˜ í´ë°±
        top, bottom = (252, 250, 255), (240, 242, 248)
        bg = Image.new("RGB", (1000, 1000))
        px = bg.load()
        for y in range(1000):
            t = y / 999
            rgb = tuple(int(top[i] * (1 - t) + bottom[i] * t) for i in range(3))
            for x in range(1000):
                px[x, y] = rgb
        out = io.BytesIO()
        bg.save(out, format="PNG")
        bg_png = out.getvalue()
    if not bg_png:
        return (None, "ë°°ê²½ ìƒì„± ì‹¤íŒ¨")

    if on_progress:
        on_progress("composite", 85)

    # 5. í•©ì„± (blocking) - core_colorsë¡œ ê·¸ë¼ë°ì´ì…˜ í†¤ ì¡°ì •
    final = await asyncio.to_thread(
        composite_thumbnail, product_png, bg_png, concept.get("core_colors") if concept else None
    )
    if not final:
        return (None, "í•©ì„± ì‹¤íŒ¨")

    if on_progress:
        on_progress("done", 100)

    data_url = "data:image/png;base64," + base64.b64encode(final).decode()
    return (data_url, None)
